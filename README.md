# Whisper-API-unity
Binds [Whisper speech to text API](https://platform.openai.com/docs/api-reference/audio) to pure C# on Unity.

See also [official document](https://platform.openai.com/docs/guides/speech-to-text).

## How to import by UnityPackageManager

Add dependencies:

```json
{
  "dependencies": {
    "com.mochineko.whisper-api": "https://github.com/mochi-neko/Whisper-API-unity.git?path=/Assets/Mochineko/Whisper_API#0.1.0",
    "com.unity.nuget.newtonsoft-json": "3.0.2",
    ...
  }
}
```

to your `mainfest.json`.

If you have already used Newtonsoft.Json on your project, remove dependency:`"com.unity.nuget.newtonsoft-json": "3.0.2",`.

## How to use speech to text by Whisper API

1. Generate API key on [OpenAI](https://platform.openai.com/account/api-keys). (Take care your API key, this is a secret information then you should not open.)
2. Create an instance of `WhisperTranscriptionConnection` with API key.
3. Set file path of speech audio e.g. `/some/path/of/file/audio.mp3`, and call `WhisperTranscriptionConnection.TranscribeFromFileAsync`.
4. Because deault response text format is JSON, you can exclude text by `APIResponseBody.FromJson(json)?.Text`.

An essential sample code of transcription with [UniTask](https://github.com/Cysharp/UniTask) is as follows:

```cs
#nullable enable
using System;
using Cysharp.Threading.Tasks;
using UnityEngine;
using UnityEngine.Assertions;
using Mochineko.Whisper_API.;
using Mochineko.Whisper_API.Transcription;

namespace XXX
{
    /// <summary>
    /// A sample component to transcribe speech by Whisper API on Unity.
    /// </summary>
    public sealed class TranscriptionSample : MonoBehaviour
    {
        /// <summary>
        /// API key generated by OpenAPI.
        /// </summary>
        [SerializeField] private string apiKey = string.Empty;

        /// <summary>
        /// File path of speech audio.
        /// </summary>
        [SerializeField] private string filePath = string.Empty;

        private WhisperTranscriptionConnection? connection;

        private void Start()
        {
            // Create instance of WhisperTranscriptionConnection.
            connection = new WhisperTranscriptionConnection(apiKey);
            
            // If you want to specify response format, language, etc..., please use other initialization:
            // connection = new WhisperTranscriptionConnection(apiKey, new APIRequestBody(
            //     file: "",
            //     model: "whisper-1",
            //     prompt: "Some prompts",
            //     responseFormat: "json",
            //     temperature: 1f,
            //     language: "ja"));
        }

        [ContextMenu(nameof(Transcribe))]
        public async void Transcribe()
        {
            string result;
            try
            {
                // Transcribe speech by Whisper speech to text API.
                result = await connection
                    .TranscribeFromFileAsync(filePath, this.GetCancellationTokenOnDestroy());
            }
            catch (Exception e)
            {
                // Exceptions should be caught.
                Debug.LogException(e);
                return;
            }

            // Default text response format is JSON.
            var text = APIResponseBody.FromJson(result)?.Text;

            // Log text result.
            Debug.Log($"[Whisper_API.Transcription.Samples] Result:\n{text}");
        }
    }
}
```

See also [Sample](https://github.com/mochi-neko/Whisper-API-unity/blob/main/Assets/Mochineko/Whisper_API.Samples/Transcription/TranscriptionSample.cs).


## Changelog

See [CHANGELOG](https://github.com/mochi-neko/Whisper-API-unity/blob/main/CHANGELOG.md)

## 3rd Party Notices

See [NOTICE](https://github.com/mochi-neko/Whisper-API-unity/blob/main/NOTICE.md).

## License

[MIT License](https://github.com/mochi-neko/Whisper-API-unity/blob/main/LICENSE)
